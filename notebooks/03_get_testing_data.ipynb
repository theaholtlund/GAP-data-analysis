{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing and Package Actions Data Retrieval\n",
    "\n",
    "This Jupyter Notebook investigates testing, actions and workflows for the GAP packages hosted on GitHub. In the redistribution of GAP and distribution GAP packages, authors will often test the compatibility of new versions of the package based on existing versions of GAP. This can be done in several ways, most frequently through tst directories in the repository. However, testing informaiton can also be completed through GitHub Actions, which is a tool for automating workflows, in the form of CI.yml files. They can also be found in PackageInfo.g files. In the context of redistribution, valuable information is found in the context of how testing is performed, especially in terms of what GAP versions are tested on, and if testing is consistent. This notebook will generate the data needed to examine testing data, which will later on be used for data validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required modules and libraries\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import requests\n",
    "import json\n",
    "from datetime import datetime\n",
    "from github import Repository, RateLimitExceededException\n",
    "\n",
    "# Get current working directory and append parent directory for module imports\n",
    "cwd = os.getcwd()\n",
    "parent_dir = os.path.dirname(cwd)\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "# Import modules from other project scripts\n",
    "from data_constants import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information on Testing and Testing Consistency\n",
    "\n",
    "Even though it is common for most GAP repositories to have a tst directory, this might be empty. Furthermore, test files can be stored in different ways, some directly in the tst directory while others could be hidden in subdirectories. Additionally, useful indicators can be uncovered by looking into and comparing the use of tst directories, GitHub actions through CI.yml files and PackageInfo.g files for testing, to study their popularity and consistency. Running the script will export the data to a 'testing_data.json' file in the 'collected_data' folder, displaying the results of the generated data per package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define global variables for the Jupyter Notebook\n",
    "org = g.get_organization(ORG_NAME_PACKAGES)\n",
    "repos = org.get_repos(type=\"public\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Functions to Retrieve Testing Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_for_tst_dir(repo: Repository) -> tuple:\n",
    "    \"\"\"Check if a 'tst' directory exists and if it is empty for a given repository.\n",
    "\n",
    "    Args:\n",
    "        repo (Repository): The GitHub repository object.\n",
    "\n",
    "    Returns:\n",
    "        tuple:\n",
    "            - tst_dir_exists (bool): True if 'tst' directory exists, False otherwise.\n",
    "            - tst_dir_empty (bool): True if 'tst' directory is empty, False otherwise.\n",
    "            - repositories_with_tests (int): The count of repositories with a 'tst' directory.\n",
    "    \"\"\"\n",
    "    tst_dir_exists = False\n",
    "    tst_dir_empty = False\n",
    "    repositories_with_tests = 0\n",
    "\n",
    "    contents = repo.get_contents(\"\")\n",
    "\n",
    "    for item in contents:\n",
    "        if item.type == \"dir\" and item.name == \"tst\":\n",
    "            tst_dir_exists = True\n",
    "            repositories_with_tests += 1\n",
    "            test_contents = repo.get_contents(item.path)\n",
    "            if len(test_contents) == 0:\n",
    "                tst_dir_empty = True\n",
    "            break\n",
    "    \n",
    "    return tst_dir_exists, tst_dir_empty, repositories_with_tests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tst_directory(repo: Repository, directory_path: str, tst_file_info: dict) -> tuple:\n",
    "    \"\"\"Recursively count '.tst' files in 'tst' directories and subdirectories of a repository.\n",
    "\n",
    "    Args:\n",
    "        repo (Repository): The GitHub repository object.\n",
    "        directory_path (str): The path of the directory to process.\n",
    "        tst_file_info (dict): Repository name, number of tst files and total tst file lines.\n",
    "\n",
    "    Returns:\n",
    "        tuple:\n",
    "            - num_tst_files (int): The total count of '.tst' files found.\n",
    "            - total_lines (int): The total number of lines in all '.tst' files.\n",
    "    \"\"\"\n",
    "    contents = repo.get_contents(directory_path)\n",
    "    num_tst_files = 0\n",
    "    total_lines = 0\n",
    "\n",
    "    for item in contents:\n",
    "        if item.type == \"file\" and item.name.endswith(\".tst\"):\n",
    "            tst_file_content = requests.get(item.download_url).text\n",
    "            lines = tst_file_content.splitlines()\n",
    "            num_tst_files += 1\n",
    "            total_lines += len(lines)\n",
    "        \n",
    "        elif item.type == \"dir\":\n",
    "            subdirectory_path = f\"{directory_path}/{item.name}\"\n",
    "            subdir_num_tst_files, subdir_total_lines = process_tst_directory(repo, subdirectory_path, tst_file_info)\n",
    "            num_tst_files += subdir_num_tst_files\n",
    "            total_lines += subdir_total_lines\n",
    "    \n",
    "    return num_tst_files, total_lines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_tst_files(repos: Repository) -> tuple:\n",
    "    \"\"\"Analyse the contents of the tst directories for all repositories.\n",
    "\n",
    "    Args:\n",
    "        repos (Repository): List of GitHub repositories.\n",
    "\n",
    "    Returns:\n",
    "        tuple:\n",
    "            - total_test_files (int): The total number of test files across all packages.\n",
    "            - tst_files_info (list): A list of dictionaries, where each dictionary represents\n",
    "                information about a test directory with files.\n",
    "    \"\"\"\n",
    "    tst_files_info = []\n",
    "    total_test_files = 0\n",
    "    total_lines = 0\n",
    "\n",
    "    for repo in repos:\n",
    "        test_exists, tst_dir_empty, _ = check_for_tst_dir(repo)\n",
    "\n",
    "        if test_exists and not tst_dir_empty:\n",
    "            tst_file_info = {\n",
    "                \"repository\": repo.name,\n",
    "                \"num_tst_files\": 0,\n",
    "                \"total_lines\": 0\n",
    "            }\n",
    "            num_tst_files, lines = process_tst_directory(repo, \"tst\", tst_file_info)\n",
    "\n",
    "            if num_tst_files > 0:\n",
    "                tst_file_info[\"num_tst_files\"] = num_tst_files\n",
    "                tst_file_info[\"total_lines\"] = lines\n",
    "                tst_files_info.append(tst_file_info)\n",
    "\n",
    "            total_test_files += num_tst_files\n",
    "            total_lines += lines\n",
    "\n",
    "    return total_test_files, tst_files_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ci_version_testing(repos: Repository) -> tuple:\n",
    "    \"\"\"Retrieve version information from CI.yml files in multiple repositories.\n",
    "\n",
    "    Args:\n",
    "        repos (Repository): List of GitHub repositories.\n",
    "\n",
    "    Returns:\n",
    "        tuple:\n",
    "            - repos_with_ci_file (int): The number of repositories that have a CI.yml file in their workflows.\n",
    "            - ci_tested_version (dict): A dictionary where the keys are repository names and the values\n",
    "                are lists of tested versions extracted from the CI.yml file.\n",
    "            - repos_without_ci_tests (list): A list of repository names that do not have CI tests.\n",
    "    \n",
    "    Raises:\n",
    "        Exception: If an error occurs while analysing a repository.\n",
    "    \"\"\"\n",
    "    repos_with_ci_file = 0\n",
    "    ci_tested_version = {}\n",
    "    repos_without_ci_tests = []\n",
    "    for repo in repos:\n",
    "        repo_name = repo.name\n",
    "        try:\n",
    "            contents = repo.get_contents(\"\")\n",
    "            has_workflows = any(content.name == \".github\" and content.type == \"dir\" for content in contents)\n",
    "            if has_workflows:\n",
    "                workflows_contents = repo.get_contents(\".github/workflows\")\n",
    "                if isinstance(workflows_contents, list):\n",
    "                    if any(file.name.lower() == \"ci.yml\" for file in workflows_contents):\n",
    "                        repos_with_ci_file += 1\n",
    "                        ci_file = next(file for file in workflows_contents if file.name.lower() == \"ci.yml\")\n",
    "                        pattern = r\"stable-(\\d+\\.\\d+)\"\n",
    "                        ci_file_contents = requests.get(ci_file.download_url).text\n",
    "                        matches = re.findall(pattern, ci_file_contents)\n",
    "                        if matches:\n",
    "                            ci_tested_version[repo_name] = matches\n",
    "                        else:\n",
    "                            repos_without_ci_tests.append(repo_name)\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred while analyzing repository '{repo_name}': {str(e)}\")\n",
    "    return repos_with_ci_file, ci_tested_version, repos_without_ci_tests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pkginfo_version_testing(repos: Repository) -> tuple:\n",
    "    \"\"\"Retrieve version information from PackageInfo.g files in multiple repositories.\n",
    "\n",
    "    Args:\n",
    "        repos (Repository): List of GitHub repositories.\n",
    "\n",
    "    Returns:\n",
    "        tuple:\n",
    "            - repos_with_pkginfo_file (int): The number of repositories that have a PackageInfo.g file.\n",
    "            - pkg_tested_version (list): A list of tuples where each tuple contains the repository name\n",
    "                and the corresponding GAP version extracted from PackageInfo.g.\n",
    "\n",
    "    Raises:\n",
    "        Exception: If an error occurs while retrieving version information.\n",
    "    \"\"\"\n",
    "    repos_with_pkginfo_file = 0\n",
    "    pkg_tested_version = []\n",
    "    for repo in repos:\n",
    "        repo_name = repo.name\n",
    "        try:\n",
    "            contents = repo.get_contents(\"\", ref=\"HEAD\")\n",
    "            pkginfo_file = next((file for file in contents if file.name.lower() == \"packageinfo.g\"), None)\n",
    "            if pkginfo_file:\n",
    "                repos_with_pkginfo_file += 1\n",
    "                pkginfo_content = pkginfo_file.decoded_content.decode(\"utf-8\")\n",
    "                version_pattern = r'GAP\\s+:=\\s+\"[^\"]*?([\\d.]+)\"'\n",
    "                version_match = re.search(version_pattern, pkginfo_content)\n",
    "                if version_match:\n",
    "                    gap_version = version_match.group(1)\n",
    "                    pkg_tested_version.append((repo_name, gap_version))\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"Error occurred while analysing repository '{repo_name}': {str(e)}\")\n",
    "    return repos_with_pkginfo_file, pkg_tested_version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_testing_data() -> None:\n",
    "    \"\"\"Export the testing data to a JSON file, while instructing the program to sleep for the\n",
    "    duration of the time it takes for the GitHub API calls limit to reset in the event that it runs out.\n",
    "\n",
    "    Args:\n",
    "        None.\n",
    "        \n",
    "    Returns:\n",
    "        None.\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        try:\n",
    "            # Export collected data to JSON file to store them for later use and better overview\n",
    "            data_folder = \"collected_data\"\n",
    "            version_testing_data = {}\n",
    "\n",
    "            total_test_files, tst_files_info = analyse_tst_files(repos)\n",
    "            repos_with_ci_file, ci_tested_version, repos_without_ci_tests = ci_version_testing(repos)\n",
    "            repos_with_pkginfo_file, pkg_tested_version = pkginfo_version_testing(repos)\n",
    "\n",
    "            # Add all repositories as keys to version_testing_data\n",
    "            for repo in repos:\n",
    "                package = repo.name\n",
    "                version_testing_data[package] = {}\n",
    "\n",
    "            for tst_file_info in tst_files_info:\n",
    "                package = tst_file_info[\"repository\"]\n",
    "                if \"num_tst_files\" in tst_file_info and \"total_lines\" in tst_file_info:\n",
    "                    version_testing_data[package][\"tst_file_count\"] = tst_file_info[\"num_tst_files\"]\n",
    "                    version_testing_data[package][\"total_lines_in_tst_files\"] = tst_file_info[\"total_lines\"]\n",
    "\n",
    "            # Add version info from CI.yml files to the dictionary\n",
    "            for package, versions in ci_tested_version.items():\n",
    "                if versions:\n",
    "                    version_testing_data[package][\"ci_file_version\"] = versions\n",
    "\n",
    "            # Add GAP version info from PackageInfo.g files to the dictionary\n",
    "            for package, version in pkg_tested_version:\n",
    "                if version:\n",
    "                    version_testing_data[package][\"pkginfo_version\"] = [version]\n",
    "\n",
    "            file_path = os.path.join(data_folder, \"testing_data.json\")\n",
    "\n",
    "            with open(file_path, \"w\") as f:\n",
    "                json.dump(version_testing_data, f, indent=4)\n",
    "\n",
    "            print(f\"Version testing data has been exported to the 'testing_data' file in the 'collected_data' folder.\")\n",
    "            break\n",
    "\n",
    "        except RateLimitExceededException:\n",
    "            remaining_requests, _ = g.rate_limiting\n",
    "            reset_time = g.rate_limiting_resettime\n",
    "            if remaining_requests < 100:\n",
    "                wait_until_reset(reset_time)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get and Export Testing Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function to export the data\n",
    "export_testing_data()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
