{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAP Data Analytics, Package Actions\n",
    "\n",
    "This Jupyter Notebook investigates tests, actions and workflows for the GAP packages hosted on GitHub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries and packages\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import requests\n",
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "# Get current working directory and append parent directory for module imports\n",
    "cwd = os.getcwd()\n",
    "parent_dir = os.path.dirname(cwd)\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "# Import modules from other project scripts\n",
    "from data_constants import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define repositories that are public for gap-packages organisation on GitHub\n",
    "org = g.get_organization(ORG_NAME_PACKAGES)\n",
    "repos = org.get_repos(type=\"public\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to check for a test directory and if it's empty\n",
    "def check_for_tst_dir(repo):\n",
    "    tst_dir_exists = False\n",
    "    tst_dir_empty = False\n",
    "\n",
    "    contents = repo.get_contents(\"\")  # Get the root directory contents of the repository\n",
    "    \n",
    "    for item in contents:\n",
    "        if item.type == \"dir\" and item.name == \"tst\":\n",
    "            tst_dir_exists = True\n",
    "            test_contents = repo.get_contents(item.path)\n",
    "            if len(test_contents) == 0:\n",
    "                tst_dir_empty = True\n",
    "            break\n",
    "    \n",
    "    return tst_dir_exists, tst_dir_empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to count repositories with test directories\n",
    "def repos_with_tst_dir(repos):\n",
    "    repositories_with_tests = 0\n",
    "    for repo in repos:\n",
    "        test_exists, test_empty = check_for_tst_dir(repo)\n",
    "        if test_exists:\n",
    "            repositories_with_tests += 1\n",
    "    return repositories_with_tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to find tst directories with .tst files\n",
    "def count_tst_files(repos):\n",
    "    tst_dirs_with_files = 0\n",
    "    for repo in repos:\n",
    "        test_exists, test_empty = check_for_tst_dir(repo)\n",
    "        if test_exists and not test_empty:\n",
    "            contents = repo.get_contents(\"tst\")  # Get the contents of the tst directory\n",
    "            tst_file_count = 0  # Counter for .tst files in the tst directory\n",
    "            for item in contents:\n",
    "                if item.type == \"file\" and item.name.endswith(\".tst\"):\n",
    "                    tst_file_count += 1\n",
    "            if tst_file_count > 0:\n",
    "                tst_dirs_with_files += 1\n",
    "    return tst_dirs_with_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to retrieve version information from CI.yml files\n",
    "def ci_version_testing(repos):\n",
    "    repos_with_ci_file = 0\n",
    "    ci_tested_version = {}\n",
    "    repos_without_ci_tests = []\n",
    "    for repo in repos:\n",
    "        repo_name = repo.name\n",
    "        try:\n",
    "            contents = repo.get_contents(\"\")\n",
    "            has_workflows = any(content.name == \".github\" and content.type == \"dir\" for content in contents)\n",
    "            if has_workflows:\n",
    "                workflows_contents = repo.get_contents(\".github/workflows\")\n",
    "                if isinstance(workflows_contents, list):\n",
    "                    if any(file.name.lower() == \"ci.yml\" for file in workflows_contents):\n",
    "                        repos_with_ci_file += 1\n",
    "                        ci_file = next(file for file in workflows_contents if file.name.lower() == \"ci.yml\")\n",
    "                        pattern = r\"stable-(\\d+\\.\\d+)\"\n",
    "                        ci_file_contents = requests.get(ci_file.download_url).text\n",
    "                        matches = re.findall(pattern, ci_file_contents)\n",
    "                        if matches:\n",
    "                            ci_tested_version[repo_name] = matches\n",
    "                        else:\n",
    "                            repos_without_ci_tests.append(repo_name)\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred while analyzing repository '{repo_name}': {str(e)}\")\n",
    "    return repos_with_ci_file, ci_tested_version, repos_without_ci_tests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to retrieve GAP version information from PackageInfo.g files\n",
    "def pkginfo_version_testing(repos):\n",
    "    repos_with_pkginfo_file = 0\n",
    "    repos_with_dependencies = 0\n",
    "    pkg_tested_version = []\n",
    "    for repo in repos:\n",
    "        repo_name = repo.name\n",
    "        try:\n",
    "            contents = repo.get_contents(\"\", ref=\"HEAD\")\n",
    "            pkginfo_file = next((file for file in contents if file.name.lower() == \"packageinfo.g\"), None)\n",
    "            if pkginfo_file:\n",
    "                repos_with_pkginfo_file += 1\n",
    "                pkginfo_content = pkginfo_file.decoded_content.decode(\"utf-8\")\n",
    "                if \"Dependencies\" in pkginfo_content:\n",
    "                    repos_with_dependencies += 1\n",
    "                version_pattern = r'GAP\\s+:=\\s+\"[^\"]*?([\\d.]+)\"'\n",
    "                version_match = re.search(version_pattern, pkginfo_content)\n",
    "                if version_match:\n",
    "                    gap_version = version_match.group(1)\n",
    "                    pkg_tested_version.append((repo_name, gap_version))\n",
    "        except Exception as e:\n",
    "            pass\n",
    "    return repos_with_pkginfo_file, repos_with_dependencies, pkg_tested_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve repositories with test directories count\n",
    "repos_with_tests = repos_with_tst_dir(repos)\n",
    "print(f\"Total repositories with test directories: {repos_with_tests}\")\n",
    "\n",
    "# Retrieve tst directories with .tst files count\n",
    "tst_dirs_with_files = count_tst_files(repos)\n",
    "print(f\"Number of tst directories with .tst files: {tst_dirs_with_files}\")\n",
    "\n",
    "# Retrieve CI.yml file information\n",
    "repos_with_ci_file, ci_tested_version, repos_without_ci_tests = ci_version_testing(repos)\n",
    "print(f\"Number of repositories with CI.yml file: {repos_with_ci_file}\")\n",
    "num_packages_without_tests = len(repos_without_ci_tests)\n",
    "if num_packages_without_tests > 0:\n",
    "    print(f\"Packages without any test data in their CI.yml files {repos_without_ci_tests}\")\n",
    "\n",
    "# Retrieve GAP version information from PackageInfo.g files\n",
    "repos_with_pkginfo_file, repos_with_dependencies, pkg_tested_version = pkginfo_version_testing(repos)\n",
    "print(f\"Number of repositories with 'PackageInfo.g' file: {repos_with_pkginfo_file}\")\n",
    "print(f\"Number of packages with 'Dependencies' section: {repos_with_dependencies}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to hold the version testing data\n",
    "version_testing_data = {}\n",
    "\n",
    "# Add version info from CI.yml files to the dictionary\n",
    "for package, versions in ci_tested_version.items():\n",
    "    if versions:\n",
    "        version_testing_data[package] = {\"ci_file_version\": versions}\n",
    "\n",
    "# Add GAP version info from PackageInfo.g files to the dictionary\n",
    "for package, version in pkg_tested_version:\n",
    "    if version:\n",
    "        version_testing_data.setdefault(package, {})[\"pkginfo_version\"] = [version]\n",
    "\n",
    "# Add test directory presence and .tst file count to the dictionary\n",
    "for repo in repos:\n",
    "    test_exists, test_empty = check_for_tst_dir(repo)\n",
    "    package = repo.name\n",
    "    version_data = version_testing_data.setdefault(package, {})\n",
    "    if test_exists and not test_empty:\n",
    "        contents = repo.get_contents(\"tst\")\n",
    "        tst_file_count = sum(1 for item in contents if item.type == \"file\" and item.name.endswith(\".tst\"))\n",
    "        version_data[\"tst_file_count\"] = tst_file_count\n",
    "\n",
    "# Define the path for the JSON file\n",
    "json_path = os.path.join(\"collected_data\", \"testing_data.json\")\n",
    "\n",
    "# Write the data to the JSON file\n",
    "with open(json_path, \"w\") as json_file:\n",
    "    json.dump(version_testing_data, json_file, indent=4)\n",
    "\n",
    "print(f\"Version testing data exported to: {json_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
