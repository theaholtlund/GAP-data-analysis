{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAP Data Analytics, Package Actions\n",
    "\n",
    "This Jupyter Notebook investigates tests, actions and workflows for the GAP packages hosted on GitHub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries and packages\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# Get current working directory and append parent directory for module imports\n",
    "cwd = os.getcwd()\n",
    "parent_dir = os.path.dirname(cwd)\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "# Import modules from other project scripts\n",
    "from data_constants import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define repositories that are public for gap-packages organisation on GitHub\n",
    "org = g.get_organization(ORG_NAME_PACKAGES)\n",
    "repos = org.get_repos(type=\"public\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to check for a test directory and if it's empty\n",
    "def check_for_tst_dir(repo):\n",
    "    tst_dir_exists = False\n",
    "    tst_dir_empty = False\n",
    "\n",
    "    contents = repo.get_contents(\"\")  # Get the root directory contents of the repository\n",
    "    repositories_with_tests = 0\n",
    "    for item in contents:\n",
    "        if item.type == \"dir\" and item.name == \"tst\":\n",
    "            tst_dir_exists = True\n",
    "            repositories_with_tests += 1\n",
    "            test_contents = repo.get_contents(item.path)\n",
    "            if len(test_contents) == 0:\n",
    "                tst_dir_empty = True\n",
    "            break\n",
    "    \n",
    "    return tst_dir_exists, tst_dir_empty, repositories_with_tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recursive function to count tst files in tst directory and subdirectories\n",
    "def process_tst_directory(repo, directory_path, tst_file_info):\n",
    "    contents = repo.get_contents(directory_path)\n",
    "    num_tst_files = 0\n",
    "    total_lines = 0\n",
    "\n",
    "    for item in contents:\n",
    "        if item.type == \"file\" and item.name.endswith(\".tst\"):\n",
    "            tst_file_content = requests.get(item.download_url).text\n",
    "            lines = tst_file_content.splitlines()\n",
    "            num_tst_files += 1\n",
    "            total_lines += len(lines)\n",
    "        \n",
    "        elif item.type == \"dir\":\n",
    "            subdirectory_path = f\"{directory_path}/{item.name}\"\n",
    "            subdir_num_tst_files, subdir_total_lines = process_tst_directory(repo, subdirectory_path, tst_file_info)\n",
    "            num_tst_files += subdir_num_tst_files\n",
    "            total_lines += subdir_total_lines\n",
    "    \n",
    "    return num_tst_files, total_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to analyse the contents of the tst directories and count tst directories with .tst files\n",
    "def analyse_tst_files(repos):\n",
    "    tst_dirs_with_files = 0\n",
    "    tst_files_info = []\n",
    "    total_test_files = 0\n",
    "    total_lines = 0\n",
    "\n",
    "    for repo in repos:\n",
    "        test_exists, tst_dir_empty, _ = check_for_tst_dir(repo)\n",
    "\n",
    "        if test_exists and not tst_dir_empty:\n",
    "            tst_file_info = {\n",
    "                \"repository\": repo.name,\n",
    "                \"num_tst_files\": 0,\n",
    "                \"total_lines\": 0\n",
    "            }\n",
    "            num_tst_files, lines = process_tst_directory(repo, \"tst\", tst_file_info)\n",
    "\n",
    "            if num_tst_files > 0:\n",
    "                tst_dirs_with_files += 1\n",
    "                tst_file_info[\"num_tst_files\"] = num_tst_files\n",
    "                tst_file_info[\"total_lines\"] = lines\n",
    "                tst_files_info.append(tst_file_info)\n",
    "\n",
    "            total_test_files += num_tst_files\n",
    "            total_lines += lines\n",
    "\n",
    "    return tst_dirs_with_files, total_test_files, tst_files_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to retrieve version information from CI.yml files\n",
    "def ci_version_testing(repos):\n",
    "    repos_with_ci_file = 0\n",
    "    ci_tested_version = {}\n",
    "    repos_without_ci_tests = []\n",
    "    for repo in repos:\n",
    "        repo_name = repo.name\n",
    "        try:\n",
    "            contents = repo.get_contents(\"\")\n",
    "            has_workflows = any(content.name == \".github\" and content.type == \"dir\" for content in contents)\n",
    "            if has_workflows:\n",
    "                workflows_contents = repo.get_contents(\".github/workflows\")\n",
    "                if isinstance(workflows_contents, list):\n",
    "                    if any(file.name.lower() == \"ci.yml\" for file in workflows_contents):\n",
    "                        repos_with_ci_file += 1\n",
    "                        ci_file = next(file for file in workflows_contents if file.name.lower() == \"ci.yml\")\n",
    "                        pattern = r\"stable-(\\d+\\.\\d+)\"\n",
    "                        ci_file_contents = requests.get(ci_file.download_url).text\n",
    "                        matches = re.findall(pattern, ci_file_contents)\n",
    "                        if matches:\n",
    "                            ci_tested_version[repo_name] = matches\n",
    "                        else:\n",
    "                            repos_without_ci_tests.append(repo_name)\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred while analyzing repository '{repo_name}': {str(e)}\")\n",
    "    return repos_with_ci_file, ci_tested_version, repos_without_ci_tests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to retrieve GAP version information from PackageInfo.g files\n",
    "def pkginfo_version_testing(repos):\n",
    "    repos_with_pkginfo_file = 0\n",
    "    repos_with_dependencies = 0\n",
    "    pkg_tested_version = []\n",
    "    for repo in repos:\n",
    "        repo_name = repo.name\n",
    "        try:\n",
    "            contents = repo.get_contents(\"\", ref=\"HEAD\")\n",
    "            pkginfo_file = next((file for file in contents if file.name.lower() == \"packageinfo.g\"), None)\n",
    "            if pkginfo_file:\n",
    "                repos_with_pkginfo_file += 1\n",
    "                pkginfo_content = pkginfo_file.decoded_content.decode(\"utf-8\")\n",
    "                if \"Dependencies\" in pkginfo_content:\n",
    "                    repos_with_dependencies += 1\n",
    "                version_pattern = r'GAP\\s+:=\\s+\"[^\"]*?([\\d.]+)\"'\n",
    "                version_match = re.search(version_pattern, pkginfo_content)\n",
    "                if version_match:\n",
    "                    gap_version = version_match.group(1)\n",
    "                    pkg_tested_version.append((repo_name, gap_version))\n",
    "        except Exception as e:\n",
    "            pass\n",
    "    return repos_with_pkginfo_file, repos_with_dependencies, pkg_tested_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the total number of test files for all the repositories\n",
    "# Use get metod so no crash if the key does not exist in the dictionary\n",
    "tst_dirs_with_files, total_test_files, tst_files_info = analyse_tst_files(repos)\n",
    "print(f\"Repositories with test directories containing files: {tst_dirs_with_files}\")\n",
    "print(f\"Total number of test files for all packages: {total_test_files}\")\n",
    "\n",
    "# Retrieve CI.yml file information\n",
    "repos_with_ci_file, ci_tested_version, repos_without_ci_tests = ci_version_testing(repos)\n",
    "print(f\"Number of repositories with CI.yml file: {repos_with_ci_file}\")\n",
    "num_packages_without_tests = len(repos_without_ci_tests)\n",
    "if num_packages_without_tests > 0:\n",
    "    print(f\"Packages without any test data in their CI.yml files {repos_without_ci_tests}\")\n",
    "\n",
    "# Retrieve GAP version information from PackageInfo.g files\n",
    "repos_with_pkginfo_file, repos_with_dependencies, pkg_tested_version = pkginfo_version_testing(repos)\n",
    "print(f\"Number of repositories with 'PackageInfo.g' file: {repos_with_pkginfo_file}\")\n",
    "print(f\"Number of packages with 'Dependencies' section: {repos_with_dependencies}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export collected data to JSON file to store them for later use and better overview\n",
    "# Define the file path for the JSON file\n",
    "data_folder = \"collected_data\"\n",
    "\n",
    "# Create a dictionary to hold the version testing data\n",
    "version_testing_data = {}\n",
    "\n",
    "# Add all repositories as keys to version_testing_data\n",
    "for repo in repos:\n",
    "    package = repo.name\n",
    "    version_testing_data[package] = {}\n",
    "\n",
    "for tst_file_info in tst_files_info:\n",
    "    package = tst_file_info[\"repository\"]\n",
    "    if \"num_tst_files\" in tst_file_info and \"total_lines\" in tst_file_info:\n",
    "        version_testing_data[package][\"tst_file_count\"] = tst_file_info[\"num_tst_files\"]\n",
    "        version_testing_data[package][\"total_lines_in_tst_files\"] = tst_file_info[\"total_lines\"]\n",
    "\n",
    "# Add version info from CI.yml files to the dictionary\n",
    "for package, versions in ci_tested_version.items():\n",
    "    if versions:\n",
    "        version_testing_data[package][\"ci_file_version\"] = versions\n",
    "\n",
    "# Add GAP version info from PackageInfo.g files to the dictionary\n",
    "for package, version in pkg_tested_version:\n",
    "    if version:\n",
    "        version_testing_data[package][\"pkginfo_version\"] = [version]\n",
    "        \n",
    "# Define the path for the JSON file\n",
    "file_path = os.path.join(data_folder, \"testing_data.json\")\n",
    "\n",
    "# Write the data to the JSON file\n",
    "with open(file_path, \"w\") as json_file:\n",
    "    json.dump(version_testing_data, json_file, indent=4)\n",
    "\n",
    "print(f\"Version testing data exported to the 'collected_data' folder.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
